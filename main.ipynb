{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import alexnet\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fftKAN import NaiveFourierKANLayer\n",
    "from fftKANConv import NaiveFourierKANConv\n",
    "\n",
    "# Import the CIFAR-10 dataset\n",
    "datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "# Create the comvolutions and avgpool adapted for a 32*32 input size\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    features = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "    features_KAN = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "        NaiveFourierKANConv(64, 64, gridsize=3, smooth_initialization=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "        NaiveFourierKANConv(192, 192, gridsize=3, smooth_initialization=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(192, 256, kernel_size=3, padding=1),\n",
    "        NaiveFourierKANConv(256, 256, gridsize=3, smooth_initialization=True),\n",
    "    )\n",
    "    avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "    classifier_AlexNet = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(256 * 4 * 4, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(4096, 10),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "    classifier_KAN = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(),\n",
    "        NaiveFourierKANLayer(256 * 4 * 4, 100, gridsize=7, smooth_initialization=True),\n",
    "        nn.Dropout(),\n",
    "        NaiveFourierKANLayer(100, 10, gridsize=5, smooth_initialization=True),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "\n",
    "    AlexNet_model = nn.Sequential(OrderedDict([\n",
    "        ('features', features),\n",
    "        ('avgpool', avgpool),\n",
    "        ('classifier', classifier_AlexNet)\n",
    "    ]))\n",
    "    KAN_model = nn.Sequential(OrderedDict([\n",
    "        ('features', features),\n",
    "        ('avgpool', avgpool),\n",
    "        ('classifier', classifier_KAN)\n",
    "    ]))\n",
    "\n",
    "    FullKAN_model = nn.Sequential(OrderedDict([\n",
    "        ('features', features_KAN),\n",
    "        ('avgpool', avgpool),\n",
    "        ('classifier', classifier_KAN)\n",
    "    ]))\n",
    "\n",
    "    return AlexNet_model, KAN_model, FullKAN_model\n",
    "\n",
    "def show_layers(model):\n",
    "    size = 32, 32, 3\n",
    "    print(\"Initial size:\", size)\n",
    "\n",
    "    for layer in [*model.features, model.avgpool, *model.classifier]:\n",
    "        print(\" \", end=\"\")\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            size = (size[0] - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1, \\\n",
    "                (size[1] - layer.kernel_size[1] + 2 * layer.padding[1]) // layer.stride[1] + 1, \\\n",
    "                layer.out_channels\n",
    "            print(\"Conv to:\", size)\n",
    "        if isinstance(layer, nn.MaxPool2d):\n",
    "            size = (size[0] - layer.kernel_size) // layer.stride + 1, \\\n",
    "                (size[1] - layer.kernel_size) // layer.stride + 1, \\\n",
    "                size[2]\n",
    "            print(\"Pool to:\", size)\n",
    "        if isinstance(layer, nn.ReLU):\n",
    "            print(\"ReLU\")\n",
    "        if isinstance(layer, nn.AdaptiveAvgPool2d):\n",
    "            size = layer.output_size[0], layer.output_size[1], size[2]\n",
    "            print(\"AvgP to:\", size)\n",
    "        if isinstance(layer, nn.Flatten):\n",
    "            size = size[0] * size[1] * size[2]\n",
    "            print(\"Flat to:\", size)\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            size = layer.out_features\n",
    "            print(\"Lin. to:\", size)\n",
    "        if isinstance(layer, NaiveFourierKANLayer):\n",
    "            size = layer.outdim\n",
    "            print(\"KAN to: \", size)\n",
    "        if isinstance(layer, NaiveFourierKANConv):\n",
    "            size = *size[:-1], layer.outdim\n",
    "            print(\"KANConv to: \", size)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35855178 \t AlexNet parameters\n",
      "7996094 \t KAN parameters\n",
      "6939198 \t Full KAN parameters\n",
      "\n",
      "33603594 \t AlexNet classifier parameters\n",
      "5744510 \t KAN classifier parameters\n",
      "5744510 \t Full KAN classifier parameters\n",
      "\n",
      "2251584 \t AlexNet features parameters\n",
      "2251584 \t KAN features parameters\n",
      "1194688 \t Full KAN features parameters\n",
      "\n",
      "AlexNet\n",
      "Initial size: (32, 32, 3)\n",
      " Conv to: (32, 32, 64)\n",
      " ReLU\n",
      " Pool to: (16, 16, 64)\n",
      " Conv to: (16, 16, 192)\n",
      " ReLU\n",
      " Pool to: (8, 8, 192)\n",
      " Conv to: (8, 8, 384)\n",
      " ReLU\n",
      " Conv to: (8, 8, 256)\n",
      " ReLU\n",
      " Conv to: (8, 8, 256)\n",
      " ReLU\n",
      " Pool to: (4, 4, 256)\n",
      " AvgP to: (4, 4, 256)\n",
      " Flat to: 4096\n",
      "  Lin. to: 4096\n",
      " ReLU\n",
      "  Lin. to: 4096\n",
      " ReLU\n",
      " Lin. to: 10\n",
      " \n",
      "KAN\n",
      "Initial size: (32, 32, 3)\n",
      " Conv to: (32, 32, 64)\n",
      " ReLU\n",
      " Pool to: (16, 16, 64)\n",
      " Conv to: (16, 16, 192)\n",
      " ReLU\n",
      " Pool to: (8, 8, 192)\n",
      " Conv to: (8, 8, 384)\n",
      " ReLU\n",
      " Conv to: (8, 8, 256)\n",
      " ReLU\n",
      " Conv to: (8, 8, 256)\n",
      " ReLU\n",
      " Pool to: (4, 4, 256)\n",
      " AvgP to: (4, 4, 256)\n",
      " Flat to: 4096\n",
      "  KAN to:  100\n",
      "  KAN to:  10\n",
      " \n",
      "Full KAN\n",
      "Initial size: (32, 32, 3)\n",
      " Conv to: (16, 16, 64)\n",
      " KANConv to:  (16, 16, 64)\n",
      " Pool to: (8, 8, 64)\n",
      " Conv to: (8, 8, 192)\n",
      " KANConv to:  (8, 8, 192)\n",
      " Pool to: (4, 4, 192)\n",
      " Conv to: (4, 4, 256)\n",
      " KANConv to:  (4, 4, 256)\n",
      " AvgP to: (4, 4, 256)\n",
      " Flat to: 4096\n",
      "  KAN to:  100\n",
      "  KAN to:  10\n",
      " "
     ]
    }
   ],
   "source": [
    "model, KAN_model, FullKAN_model = get_model()\n",
    "\n",
    "# Print the number of parameters of the full models\n",
    "print(sum(p.numel() for p in model.parameters()), \"\\t AlexNet parameters\")\n",
    "print(sum(p.numel() for p in KAN_model.parameters()), \"\\t KAN parameters\")\n",
    "print(sum(p.numel() for p in FullKAN_model.parameters()), \"\\t Full KAN parameters\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the number of parameters of the classifiers\n",
    "print(sum(p.numel() for p in model.classifier.parameters()), \"\\t AlexNet classifier parameters\")\n",
    "print(sum(p.numel() for p in KAN_model.classifier.parameters()), \"\\t KAN classifier parameters\")\n",
    "print(sum(p.numel() for p in FullKAN_model.classifier.parameters()), \"\\t Full KAN classifier parameters\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the number of parameters of the features\n",
    "print(sum(p.numel() for p in model.features.parameters()), \"\\t AlexNet features parameters\")\n",
    "print(sum(p.numel() for p in KAN_model.features.parameters()), \"\\t KAN features parameters\")\n",
    "print(sum(p.numel() for p in FullKAN_model.features.parameters()), \"\\t Full KAN features parameters\")\n",
    "\n",
    "# Print the size of the layers\n",
    "print(\"\\nAlexNet\")\n",
    "show_layers(model)\n",
    "\n",
    "print(\"\\nKAN\")\n",
    "show_layers(KAN_model)\n",
    "\n",
    "print(\"\\nFull KAN\")\n",
    "show_layers(FullKAN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the AlexNet model\n",
    "model, _, _ = get_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "pbar = tqdm(range(10)) \n",
    "for epoch in pbar:\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'AlexNet Loss: {loss:02f}')\n",
    "    torch.save(model.state_dict(), \"alexnet_cifar10.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), \"alexnet_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 79.92%\n",
      "Accuracy of plane: 82.2%\n",
      "Accuracy of car: 84.3%\n",
      "Accuracy of bird: 75.3%\n",
      "Accuracy of cat: 60.1%\n",
      "Accuracy of deer: 75.3%\n",
      "Accuracy of dog: 70.3%\n",
      "Accuracy of frog: 89.2%\n",
      "Accuracy of horse: 85.8%\n",
      "Accuracy of ship: 88.1%\n",
      "Accuracy of truck: 91.2%\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model, _, _ = get_model()\n",
    "model.load_state_dict(torch.load(\"alexnet_cifar10.pth\"))\n",
    "\n",
    "# Accuracy of the AlexNet model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n",
    "\n",
    "# Accuracy of the AlexNet model per class\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KAN Loss: 0.070824, weight mean: -0.000004: 100%|██████████| 10/10 [4:53:11<00:00, 1759.19s/it] \n"
     ]
    }
   ],
   "source": [
    "alexnet, model, _ = get_model()\n",
    "\n",
    "# Use pretrained AlexNet model to initialize the KAN model\n",
    "alexnet.load_state_dict(torch.load(\"alexnet_cifar10.pth\"))\n",
    "model.features = alexnet.features\n",
    "model.avgpool = alexnet.avgpool\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "pbar = tqdm(range(10))\n",
    "for epoch in pbar:\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # We need to clip the grad norms to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'KAN Loss: {loss:02f}, weight mean: {model.classifier[2].fouriercoeffs.mean():02f}')\n",
    "    torch.save(model.state_dict(), \"kan_cifar10.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), \"kan_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 81.85%\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "_, model, _ = get_model()\n",
    "model.load_state_dict(torch.load(\"kan_cifar10.pth\"))\n",
    "\n",
    "# Accuracy of the KAN model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n",
    "\n",
    "# Accuracy of the KAN model per class\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 81.85%\n",
      "Accuracy of plane: 87.1%\n",
      "Accuracy of car: 90.1%\n",
      "Accuracy of bird: 67.8%\n",
      "Accuracy of cat: 65.4%\n",
      "Accuracy of deer: 86.7%\n",
      "Accuracy of dog: 71.8%\n",
      "Accuracy of frog: 85.8%\n",
      "Accuracy of horse: 81.0%\n",
      "Accuracy of ship: 88.5%\n",
      "Accuracy of truck: 87.8%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full KAN Loss: 2.750406, weight mean: 0.000002:   0%|          | 0/10 [30:49<?, ?it/s] "
     ]
    }
   ],
   "source": [
    "# Train the Full KAN model\n",
    "_, _, model = get_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "pbar = tqdm(range(10))\n",
    "for epoch in pbar:\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # We need to clip the grad norms to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'Full KAN Loss: {loss:02f}, weight mean: {model.classifier[2].fouriercoeffs.mean():02f}')\n",
    "    torch.save(model.state_dict(), \"fullkan_cifar10.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), \"fullkan_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "_, _, model = get_model()\n",
    "model.load_state_dict(torch.load(\"fullkan_cifar10.pth\"))\n",
    "\n",
    "# Accuracy of the Full KAN model\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
