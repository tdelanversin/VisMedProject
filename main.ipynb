{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import alexnet\n",
    "from torchvision import datasets\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fftKAN import NaiveFourierKANLayer\n",
    "\n",
    "# Import the CIFAR-10 dataset\n",
    "datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "# Create the comvolutions and avgpool adapted for a 32*32 input size\n",
    "\n",
    "def get_model():\n",
    "    features = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "    avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "    classifier_AlexNet = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(256 * 4 * 4, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(4096, 10),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "    classifier_KAN = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(),\n",
    "        NaiveFourierKANLayer(256 * 4 * 4, 100, gridsize=7, smooth_initialization=True),\n",
    "        nn.Dropout(),\n",
    "        NaiveFourierKANLayer(100, 10, gridsize=5, smooth_initialization=True),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "\n",
    "    AlexNet_model = nn.Sequential(OrderedDict([\n",
    "        ('features', features),\n",
    "        ('avgpool', avgpool),\n",
    "        ('classifier', classifier_AlexNet)\n",
    "    ]))\n",
    "    KAN_model = nn.Sequential(OrderedDict([\n",
    "        ('features', features),\n",
    "        ('avgpool', avgpool),\n",
    "        ('classifier', classifier_KAN)\n",
    "    ]))\n",
    "\n",
    "    return AlexNet_model, KAN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35855178 \t AlexNet parameters\n",
      "7996094 \t KAN parameters\n",
      "33603594 \t AlexNet classifier parameters\n",
      "5744510 \t KAN classifier parameters\n",
      "2251584 \t AlexNet features parameters\n",
      "2251584 \t KAN features parameters\n"
     ]
    }
   ],
   "source": [
    "AlexNet_model, KAN_model = get_model()\n",
    "\n",
    "# Print the number of parameters of the full models\n",
    "print(sum(p.numel() for p in AlexNet_model.parameters()), \"\\t AlexNet parameters\")\n",
    "print(sum(p.numel() for p in KAN_model.parameters()), \"\\t KAN parameters\")\n",
    "\n",
    "# Print the number of parameters of the classifiers\n",
    "print(sum(p.numel() for p in AlexNet_model.classifier.parameters()), \"\\t AlexNet classifier parameters\")\n",
    "print(sum(p.numel() for p in KAN_model.classifier.parameters()), \"\\t KAN classifier parameters\")\n",
    "\n",
    "# Print the number of parameters of the features\n",
    "print(sum(p.numel() for p in AlexNet_model.features.parameters()), \"\\t AlexNet features parameters\")\n",
    "print(sum(p.numel() for p in KAN_model.features.parameters()), \"\\t KAN features parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv to: 32\n",
      "Pool to: 16\n",
      "Conv to: 16\n",
      "Pool to: 8\n",
      "Conv to: 8\n",
      "Conv to: 8\n",
      "Conv to: 8\n",
      "Pool to: 4\n"
     ]
    }
   ],
   "source": [
    "AlexNet_model, _ = get_model()\n",
    "\n",
    "size = 32\n",
    "for layer in AlexNet_model.features:\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        size = (size - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1\n",
    "        print(\"Conv to:\", size)\n",
    "    if isinstance(layer, nn.MaxPool2d):\n",
    "        size = (size - layer.kernel_size) // layer.stride + 1\n",
    "        print(\"Pool to:\", size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the AlexNet model\n",
    "model, _ = get_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "pbar = tqdm(range(10)) \n",
    "for epoch in pbar:\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'AlexNet Loss: {loss:02f}')\n",
    "    torch.save(model.state_dict(), \"alexnet_cifar10.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), \"alexnet_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 79.92%\n",
      "Accuracy of plane: 82.2%\n",
      "Accuracy of car: 84.3%\n",
      "Accuracy of bird: 75.3%\n",
      "Accuracy of cat: 60.1%\n",
      "Accuracy of deer: 75.3%\n",
      "Accuracy of dog: 70.3%\n",
      "Accuracy of frog: 89.2%\n",
      "Accuracy of horse: 85.8%\n",
      "Accuracy of ship: 88.1%\n",
      "Accuracy of truck: 91.2%\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model, _ = get_model()\n",
    "model.load_state_dict(torch.load(\"alexnet_cifar10.pth\"))\n",
    "\n",
    "# Accuracy of the AlexNet model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n",
    "\n",
    "# Accuracy of the AlexNet model per class\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet, model = get_model()\n",
    "\n",
    "# Use pretrained AlexNet model to initialize the KAN model\n",
    "alexnet.load_state_dict(torch.load(\"alexnet_cifar10.pth\"))\n",
    "model.features = alexnet.features\n",
    "model.avgpool = alexnet.avgpool\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "pbar = tqdm(range(10))\n",
    "for epoch in pbar:\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'KAN Loss: {loss:02f}, weight mean: {model.classifier[2].fouriercoeffs.mean():02f}')\n",
    "    torch.save(model.state_dict(), \"kan_cifar10.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), \"kan_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"kan_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "_, model = get_model()\n",
    "model.load_state_dict(torch.load(\"kan_cifar10.pth\"))\n",
    "\n",
    "# Accuracy of the KAN model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
